This file provides the most complete and detailed reference on the Godspeed project. When giving examples or explanations, draw from this project as it represents the ideal setup, configurations, and features. Use This Godspeed Project as a primary example to ensure responses align with best practices and project standards.

Godspeed Project Scaffolding
Framework will give you below folder structure.


```
    .
    ├── src
        ├── docs
        │    └── http-swagger.json 
        ├── datasources
        │   ├── types
        │   |    └── axios.ts
        |   |
        │   └── api.yaml
        │
        ├── events
        |   |
        │   └── helloworld.yaml
        |
        ├── eventsources
        │   ├── types
        │   |    └── express.ts
        |   |
        │   └── http.yaml
        |
        └── functions
            |
            └── helloworld.yaml
```

---- Content from: aws.ts ----

import { GSContext, GSDataSource, GSStatus, PlainObject } from "@godspeedsystems/core";
//Some example client mappings. Developer should set the mappings of all 
//service types she needs in their datasource's instance's yaml file. 
//If she sets even one mapping. that is used, and this one is ignored.
const SERVICE_CLIENT_MAPPINGS: PlainObject = {
  dynamodb: 'DynamoDB',
  s3: 'S3',
  lambda: 'Lambda',
  ssm: 'SSM',
  sqs: 'SQS'
};

export default class AWSDataSource extends GSDataSource {
  async initClient(): Promise<PlainObject> {
    const client = await this.initializeClients();
    return client;
  }
  /**
   * Config will allow multiple clients initializations of the each type of service
   * 
   * For ex. A sample aws services config
   * 
   * ```yaml
   * type:aws
   * default_client_config: # default config. Config will be given. As per AWS sdk API specs
   * services:
   *  s3_1:
   *    type: s3
   *    config: #will override default
   *  s3_2:
   *    type: s3
   *  dynamodb:
   *    type: dynamodb
   * ```
   */


  async initializeClients(): Promise<PlainObject> {
    const dsConfig: PlainObject = (this as GSDataSource).config;
    const serviceModules: PlainObject = {};
    const clients: PlainObject = {};
    if (!dsConfig.services) {
      throw new Error(`The AWS datasource config in ${dsConfig.name}.yaml does not have any services declared under the key 'services'`);
    }
    const serviceClientMappings: PlainObject = (this as GSDataSource).config.types || SERVICE_CLIENT_MAPPINGS;
    for (let serviceName of Object.keys(dsConfig.services)) {
      const serviceConfig = dsConfig.services[serviceName];
      const serviceType = serviceConfig.type;
      if (!serviceType) {
        throw new Error(`The AWS datasource config in ${dsConfig.name}.yaml does not define service 'type' for serviceName ${serviceName}. Define the type of service like s3, dynamodb etc`);
      }
      let serviceModule = serviceModules[serviceType];
      if (!serviceModule) {
        const clientLibrary = await import(`@aws-sdk/client-${serviceType}`);
        serviceModule = clientLibrary[serviceClientMappings[serviceType]];
        serviceModules[serviceType] = serviceModule;
      }
      const Constructor = serviceModule;
      const config = serviceConfig.config || dsConfig.default_client_config;
      config.https = {
         rejectUnauthorized: false
      }
      const serviceClient = new Constructor(config);
      clients[serviceName] = serviceClient;
    }
    return clients;
  }

  /**
   * The `fnNameInWorkflow` arg represets the `fn` name which is like
   * `datasource.<aws_instance_name>.<service_name>.<method_name>`
   * For ex. `datasource.aws.s3_1.createTable`
   * @param ctx 
   * @param args 
   * @returns 
   */
  async execute(ctx: GSContext, args: PlainObject): Promise<GSStatus> {
    const {

      meta: { entityType: serviceName, method },
      ...rest
    } = args;
    try {
      // fn validity checks
      // const fnParts = this.isFnValid(fnNameInWorkflow, ctx);
      // if (!fnParts) {
      //   throw new Error();
      // }
      if (!serviceName) {
        ctx.childLogger.error("Invalid aws datasource fn. Service name not found. fn is epxected to be of this format: datasource.<aws_instance_name>.<service_name>.<method_name>");
        return new GSStatus(false, 500, undefined, { message: "Internal server error" });
      }
      if (!method) {
        ctx.childLogger.error("Invalid aws datasource fn. Method's name Not found. fn is epxected to be of this format: datasource.<aws_instance_name>.<service_name>.<method_name>");
        return new GSStatus(false, 500, undefined, { message: "Internal server error" });
      }
      // let [, , serviceName, method] = fnParts;
      //@ts-ignore
      const serviceClient = this.client && this.client[serviceName];

      if (!serviceClient) {
        ctx.childLogger.error(`Invalid AWS service name '${serviceName}'. Make sure to enable this service in the aws datasource's yaml config file.`);
        return new GSStatus(false, 500, undefined, { message: "Internal server error" });
      }

      if (typeof serviceClient[method] === 'function') {
        //Invoke the method
        const response = await serviceClient[method](rest);
        return new GSStatus(true, 200, undefined, response);
      } else {

        ctx.childLogger.error(`Invalid method '${method}' called for datasource.aws.${serviceName}`);
        return new GSStatus(false, 500, undefined, { message: "Internal server error" });
      }

    } catch (error: any) {
      ctx.childLogger.error(`Error encountered in executing ${serviceName}.${method}. ${error} %o`, error);
      return new GSStatus(false, error.$metadata?.httpStatusCode || 500, undefined, { message: "Internal server error" });
    }
  }

  // isFnValid(fnNameInWorkflow: string, ctx: GSContext): string[] | undefined {
  //   if (!fnNameInWorkflow) {
  //     ctx.childLogger.error("fn can not be null or undefined");
  //     return;
  //   }
  //   const fnParts: string[] = fnNameInWorkflow.split('.');
  //   if (fnParts.length !== 4) {
  //     ctx.childLogger.error("Invalid aws datasource fn. fn is epxected to be of this format: datasource.<aws_instance_name>.<service_name>.<method_name>");
  //     return;
  //   }
  //   let [, , serviceName, method] = fnParts;
  //   if (!serviceName) {
  //     ctx.childLogger.error("Invalid aws datasource fn. Service name not found. fn is epxected to be of this format: datasource.<aws_instance_name>.<service_name>.<method_name>");
  //     return;
  //   }
  //   if (!method) {
  //     ctx.childLogger.error("Invalid aws datasource fn. Method's name Not found. fn is epxected to be of this format: datasource.<aws_instance_name>.<service_name>.<method_name>");
  //     return;
  //   }

  //   return fnParts;
  // }


}


const SourceType = 'DS';
const Type = 'aws'; // this is the loader file of the plugin, So the final loader file will be `types/${Type.js}`
const CONFIG_FILE_NAME = 'aws'; // in case of event source, this also works as event identifier, and in case of datasource works as datasource name
const DEFAULT_CONFIG = {};

export {
  AWSDataSource as DataSource,
  SourceType,
  Type,
  CONFIG_FILE_NAME,
  DEFAULT_CONFIG
}


---- Content from: axios.ts ----

import { DataSource } from "@godspeedsystems/plugins-axios-as-datasource";
export default DataSource;


---- Content from: kafka.ts ----


    import { DataSource } from '@godspeedsystems/plugins-kafka-as-datasource-as-eventsource';
    export default DataSource;
              

---- Content from: mem-cache.ts ----

import { GSCachingDataSource, GSContext, PlainObject, logger} from "@godspeedsystems/core";
const logAttrs = {'memcache_file': 'src/datasources/types/mem-cache.ts'};
export default class MemCacheDs extends GSCachingDataSource {
    set(key: string, val: any, options: { EX?: number | undefined; PX?: number | undefined; EXAT?: number | undefined; NX?: boolean | undefined; XX?: boolean | undefined; KEEPTTL?: boolean | undefined; GET?: boolean | undefined; }) {
        logger.debug(logAttrs, 'set key %s %o', key, this.client)
        //@ts-ignore
        this.client[key] = val;
        logger.debug(logAttrs, 'after set %s %o', key, this.client)

    }
    get(key: string) {
        logger.debug(logAttrs, 'get %s %o', key, this.client);
        //@ts-ignore
        return this.client[key];
    }
    del(key: string) {
        logger.debug(logAttrs, 'del %s %o', key, this.client)
        //@ts-ignore
        delete this.client[key];
        logger.debug(logAttrs, 'after del %s %o', key, this.client)

    }
    protected async initClient(): Promise<PlainObject> {
        this.client = {};
        return this.client;
    }
    execute(ctx: GSContext, args: PlainObject): Promise<any> {
        throw new Error("Method not implemented.");
    }

}


---- Content from: prisma.ts ----


    import { DataSource } from '@godspeedsystems/plugins-prisma-as-datastore';
    export default DataSource;
                

---- Content from: salesforce.ts ----


    import { DataSource } from '@godspeedsystems/plugins-salesforce-as-datasource-as-eventsource';
    export default DataSource;
              

---- Content from: aws.yaml ----

type: aws
default_client_config:
  region: <%config.aws.region%>
  credentials:
    accessKeyId: <%config.aws.accessKeyId%>
    secretAccessKey: <%config.aws.secretAccessKey%>

services:
  s3:
    type: s3
  # s3_1:
  #   type: s3
    # Can have API specific configuration override on top of default config
    # config:
    #   region: <%config.aws.region%>
    #   credentials:
    #     accessKeyId: <%config.aws.accessKeyId%>
    #     secretAccessKey: <%config.aws.secretAccessKey%>
  dynamodb:
    type: dynamodb
  # sqs:
  #   type: sqs
  # ssm:
  #   type: ssm
  # lamdba:
  #   type: lambda

# service type is the name of the npm module for ex. @aws-sqk/client-dynamodb or @aws-sqk/client-s3 etc
# The `types` key can have service type to sdk's client names mappings when coding
types: 
  dynamodb: DynamoDB
  s3: S3
  lambda: Lambda
  ssm: SSM
  sqs: SQS

---- Content from: in_mem_cache.yaml ----

type: mem-cache

---- Content from: kafka.yaml ----

type: kafka
clientId: <% config.kafka.client_id %>
brokers: <% config.kafka.brokers %>


---- Content from: kyc.yaml ----

type: axios
base_url: https://httpbin.org

# print all api calls in curl format
curlifiedLogs: true 

# Authentication of API calls with token refresh logic
authn: 
  fn: my_bank.authn
  refreshOn:
    statusCode: [401]

# Common headers to be set in all API calls
headers:
  Content-Type: application/json
  Cookie: <%mappings.my_bank.auth_workflow_cookie%>

# Retry logic for failed API calls for ex on Internal server errors or request timeouts
retry:
    when: #the condition
      status: [500, 503] # an array or single value of codes (optional). Default 500
      message: my custom expected message for retry #And (optionally) when response has this message
    max_attempts: 5
    type: constant # or random, exponential
    interval: PT15s
    # type: exponential
    # min_interval: PT5s
    # max_internal: PT15s
    # type: random
    # min_interval: PT5s
    # max_internal: PT15s

# Any other configurations you need to reuse in datasource initialization or method executions
auth_url: https://httpbin.org
some_config: 'my_config_setting'

---- Content from: lending_service_db.prisma ----

datasource db {
  provider = "postgresql" // or "mysql", "sqlite", "sqlserver" etc.
  url      = env("POSTGRES_URL")
}

generator client {
  provider = "prisma-client-js"
  output   = "./prisma-clients/lending_service_db"
  previewFeatures = ["metrics"]
}

model User {
  id               Int               @id @default(autoincrement())
  pan_number            String            @unique ///@encrypted
  // password         String            ///@encrypted
  // name             String?
  loanApplications LoanApplication[]
}

model LoanApplication {
  id             Int             @id @default(autoincrement())
  createdAt      DateTime        @default(now())
  updatedAt      DateTime        @updatedAt
  status         String          // e.g. "pending", "approved", "rejected"
  amount         Float
  interest       Float
  duration       Int
  bank_name      String
  userId         Int             // Foreign key to associate with User
  // loanProductId  Int             // Foreign key to associate with LoanProduct
  user           User            @relation(fields: [userId], references: [id])
  // loanProduct    LoanProduct     @relation(fields: [loanProductId], references: [id])
}

// model LoanProduct {
//   id               Int               @id @default(autoincrement())
//   name             String
//   interestRate     Float             // e.g. 5.5 for 5.5%
//   termLength       Int               // Length of loan term in months
//   loanApplications LoanApplication[]
// }

---- Content from: lms.yaml ----

type: axios
base_url: https://httpbin.org

# print all api calls in curl format
curlifiedLogs: true 

# Authentication of API calls with token refresh logic
authn: 
  fn: my_bank.authn
  refreshOn:
    statusCode: [401]

# Common headers to be set in all API calls
headers:
  Content-Type: application/json
  Cookie: <%mappings.my_bank.auth_workflow_cookie%>

# Retry logic for failed API calls for ex on Internal server errors or request timeouts
retry:
    when: #the condition
      status: [500, 503] # an array or single value of codes (optional). Default 500
      message: my custom expected message for retry #And (optionally) when response has this message
    max_attempts: 5
    type: constant # or random, exponential
    interval: PT15s
    # type: exponential
    # min_interval: PT5s
    # max_internal: PT15s
    # type: random
    # min_interval: PT5s
    # max_internal: PT15s

# Any other configurations you need to reuse in datasource initialization or method executions
auth_url: https://httpbin.org
some_config: 'my_config_setting'

---- Content from: my_bank.yaml ----

type: axios
base_url: https://httpbin.org

# print all api calls in curl format
curlifiedLogs: true 

# Authentication of API calls with token refresh logic
authn: 
  fn: my_bank.authn
  refreshOn:
    statusCode: [401]

# Common headers to be set in all API calls
headers:
  Content-Type: application/json
  Cookie: <%mappings.my_bank.auth_workflow_cookie%>

# Retry logic for failed API calls for ex on Internal server errors or request timeouts
retry:
    when: #the condition
      status: [500, 503] # an array or single value of codes (optional). Default 500
      message: my custom expected message for retry #And (optionally) when response has this message
    max_attempts: 5
    type: constant # or random, exponential
    interval: PT15s
    # type: exponential
    # min_interval: PT5s
    # max_internal: PT15s
    # type: random
    # min_interval: PT5s
    # max_internal: PT15s

# Any other configurations you need to reuse in datasource initialization or method executions
auth_url: https://httpbin.org
some_config: 'my_config_setting'

---- Content from: rule_engine.yaml ----

type: axios
base_url: https://httpbin.org

# print all api calls in curl format
curlifiedLogs: true 

# Authentication of API calls with token refresh logic
authn: 
  fn: my_bank.authn
  refreshOn:
    statusCode: [401]

# Common headers to be set in all API calls
headers:
  Content-Type: application/json
  Cookie: <%mappings.my_bank.auth_workflow_cookie%>

# Retry logic for failed API calls for ex on Internal server errors or request timeouts
retry:
    when: #the condition
      status: [500, 503] # an array or single value of codes (optional). Default 500
      message: my custom expected message for retry #And (optionally) when response has this message
    max_attempts: 5
    type: constant # or random, exponential
    interval: PT15s
    # type: exponential
    # min_interval: PT5s
    # max_internal: PT15s
    # type: random
    # min_interval: PT5s
    # max_internal: PT15s

# Any other configurations you need to reuse in datasource initialization or method executions
auth_url: https://httpbin.org
some_config: 'my_config_setting'

---- Content from: lending_service_db.yaml ----

User:
  type: object
  required:
    - pan_number
  additionalProperties: false
  properties:
    pan_number:
      type: string
LoanApplication:
  type: object
  required:
    - updatedAt
    - status
    - amount
    - interest
    - duration
    - bank_name
    - userId
  properties:
    createdAt:
      type: string
      format: date-time
    updatedAt:
      type: string
      format: date-time
    status:
      type: string
    amount:
      type: number
    interest:
      type: number
    duration:
      type: integer
    bank_name:
      type: string
    userId:
      type: integer


---- Content from: los.yaml ----

loan_offers:
  type: object
  required: ['pan_number']
  properties:
    pan_number:
      type: string
      example: AKJPG88DD

apply_loan:
  type: object
  required: ['pan_number', 'bank_name']
  properties:
    pan_number:
      type: string
      example: AKJPG88DD
    bank_name:
      type: string
      example: my_bank
    panCardFile:
      type: string
      format: binary    

    
    

---- Content from: kafka_to_db.yaml ----

# consuming kafka event from topic new_loan
kafka.new_loan.grpId1:
  id: kafka_new_loan_event
  fn: db_sync.kafka_to_db
  summary: listen on new loan and create a database entry
  description: consume data from kafka and transfer data into DB
  data: #kafka message body validation (the kafka plugin does JSON.parse(message))
    description: Kafka Message data payload
    required: true
    content:
      application/json:
        schema:
          type: string
          required:
            [
              pan_number,
              amount,
              interest,
              duration,
              bank_name
            ]
          properties:
            pan_number:
              type: string
            bank_name:
              type: string
            interest:
              type: float
            duration:
              type: integer
            amount:
              type: float
  log:
    attributes:
      event_type: on_create
      event_entity_type: Loan

---- Content from: loanapplication.yaml ----

# ONE
http & graphql.get./lending_service_db/loanapplication/{id}:
  summary: Fetch LoanApplication
  description: Fetch LoanApplication from database
  fn: com.biz.lending_service_db.loanapplication.one
  params:
    - name: id
      in: path
      required: true
      schema:
        type: string
  responses:
    content:
      '200':
        application/json:
          schema:
            type: object
  log:
    attributes:
      event_entity_id: params.id
      event_user_role: user.role
      event_type: find_one
      event_entity_type: LoanApplication

# CREATE
http & graphql.post./lending_service_db/loanapplication:
  summary: Create a new LoanApplication
  description: Create LoanApplication from database
  fn: com.biz.lending_service_db.loanapplication.create
  body:
    content:
      application/json:
        schema:
          $ref: '#/definitions/lending_service_db/LoanApplication'
  responses:
    content:
      '201':
        application/json:
          schema:
            type: object
  log:
    attributes:
      event_user_role: user.role
      event_type: create
      event_entity_type: LoanApplication
# UPDATE
http & graphql.put./lending_service_db/loanapplication/{id}:
  summary: Update a LoanApplication
  description: Update LoanApplication from database
  fn: com.biz.lending_service_db.loanapplication.update
  body:
    content:
      application/json:
        schema:
          $ref: '#/definitions/lending_service_db/LoanApplication'
  params:
    - name: id
      in: path
      required: true
      schema:
        type: string
  responses:
    content:
      '204':
        application/json:
          schema:
            type: object
  log:
    attributes:
      event_entity_id: params.id
      event_user_role: user.role
      event_type: update
      event_entity_type: LoanApplication

# DELETE
http & graphql.delete./lending_service_db/loanapplication/{id}:
  summary: Delete a LoanApplication
  description: Delete LoanApplication from database
  fn: com.biz.lending_service_db.loanapplication.delete
  params:
    - name: id
      in: path
      required: true
      schema:
        type: string
  responses:
    content:
      '202':
        application/json:
          schema:
            type: object
  log:
    attributes:
      event_entity_id: params.id
      event_user_role: user.role
      event_type: delete
      event_entity_type: LoanApplication

# SEARCH
http & graphql.post./lending_service_db/loanapplication/search:
  summary: Fetch multiple LoanApplication
  description: Fetch multiple LoanApplication from database
  fn: com.biz.lending_service_db.loanapplication.search
  body:
    content:
      application/json:
        schema:
          type: object
          example: {"include": {"user": {"select": {"pan_number": true}}}, "where": {"userId": 19}}

  responses:
    content:
      '200':
        application/json:
          schema:
            type: array
            items:
              $ref: '#/definitions/lending_service_db/LoanApplication'
  log:
    attributes:
      event_user_role: user.role
      event_type: search
      event_entity_type: LoanApplication



---- Content from: user.yaml ----

# ONE
http & graphql.get./lending_service_db/user/{id}:
  summary: Fetch User
  description: Fetch User from database
  fn: com.biz.lending_service_db.user.one
  params:
    - name: id
      in: path
      required: true
      schema:
        type: string
  responses:
    content:
      '200':
        application/json:
          schema:
            type: object
  log:
    attributes:
      event_user_id: params.id
      event_user_role: user.role
      event_type: find_one
      event_entity_type: User


# CREATE
http & graphql.post./lending_service_db/user:
  summary: Create a new User
  description: Create User from database
  fn: com.biz.lending_service_db.user.create
  body:
    content:
      application/json:
        schema:
          $ref: '#/definitions/lending_service_db/User'
  responses:
    content:
      '201':
        application/json:
          schema:
            type: object
  log:
    attributes:
      event_user_role: user.role
      event_type: create
      event_entity_type: User

# UPDATE
http & graphql.put./lending_service_db/user/{id}:
  summary: Update a User
  description: Update User from database
  fn: com.biz.lending_service_db.user.update
  body:
    content:
      application/json:
        schema:
          $ref: '#/definitions/lending_service_db/User'
  params:
    - name: id
      in: path
      required: true
      schema:
        type: string
  responses:
    content:
      '204':
        application/json:
          schema:
            type: object
  log:
    attributes:
      event_user_id: params.id
      event_user_role: user.role
      event_type: update
      event_entity_type: User

# DELETE
http & graphql.delete./lending_service_db/user/{id}:
  summary: Delete a User
  description: Delete User from database
  fn: com.biz.lending_service_db.user.delete
  params:
    - name: id
      in: path
      required: true
      schema:
        type: string
  responses:
    content:
      '202':
        application/json:
          schema:
            type: object
  log:
    attributes:
      event_user_id: params.id
      event_user_role: user.role
      event_type: delete
      event_entity_type: User

# SEARCH
http & graphql.post./lending_service_db/user/search:
  summary: Fetch multiple User
  description: Fetch multiple User from database
  fn: com.biz.lending_service_db.user.search
  body:
    content:
      application/json:
        schema:
          type: object
          example: {"include": {"loanApplications": true}, "where": {"pan_number": "AKJPG8855"}}

  responses:
    content:
      '200':
        application/json:
          schema:
            type: array
            items:
              $ref: '#/definitions/lending_service_db/User'
  log:
    attributes:
      event_user_role: user.role
      event_type: search
      event_entity_type: User


---- Content from: appy_for_loan.yaml ----

http & graphql.post./apply/loan:
  summary: Apply for loan 
  description:  Apply for loan
  fn: los.apply_for_loan
  body:
    content:
      multipart/form-data:
         schema:
          $ref: '#/definitions/los/apply_loan'
  responses:
    200:
      content:
        application/json:
          schema:
            type: object

  log:
    attributes:
      event_type: apply_loan

---- Content from: make_loan_offers.yaml ----

http & graphql.post./fetch/loan/offers:
  summary: Fetch loan offer from banks
  description:  Fetch loan offer from banks
  fn: los.fetch_loan_offers
  body:
    content:
      application/json:
        schema:
          $ref: '#/definitions/los/loan_offers'
  responses:
    content:
      application/json:
        schema:
          type: object
  log:
    attributes:
      event_type: fetch_loan_offers
      event_entity_type: LoanOffer

---- Content from: express.ts ----

import { EventSource } from "@godspeedsystems/plugins-express-as-http";

export default EventSource;


---- Content from: graphql.ts ----


import { EventSource } from '@godspeedsystems/plugins-graphql-as-eventsource';
export default EventSource;

---- Content from: kafka.ts ----


    import { EventSource } from '@godspeedsystems/plugins-kafka-as-datasource-as-eventsource';
    export default EventSource;
              

---- Content from: salesforce.ts ----


    import { EventSource } from '@godspeedsystems/plugins-salesforce-as-datasource-as-eventsource';
    export default EventSource;
              

---- Content from: graphql.graphql ----

input apply_loanInput {
  pan_number: String!
  bank_name: String!
  panCardFile: String
}

scalar JSON

input loan_offersInput {
  pan_number: String!
}

input LoanApplicationInput {
  createdAt: String
  updatedAt: String!
  status: String!
  amount: Float!
  interest: Float!
  duration: Int!
  bank_name: String!
  userId: Int!
}

type Mutation {
  """Update LoanApplication from database"""
  Update_a_LoanApplication(id: String!, body: LoanApplicationInput): JSON!

  """Delete LoanApplication from database"""
  Delete_a_LoanApplication(id: String!): JSON!

  """Create LoanApplication from database"""
  Create_a_new_LoanApplication(body: LoanApplicationInput): JSON!

  """Fetch multiple LoanApplication from database"""
  Fetch_multiple_LoanApplication(body: JSON): JSON!

  """Update User from database"""
  Update_a_User(id: String!, body: UserInput): JSON!

  """Delete User from database"""
  Delete_a_User(id: String!): JSON!

  """Create User from database"""
  Create_a_new_User(body: UserInput): JSON!

  """Fetch multiple User from database"""
  Fetch_multiple_User(body: JSON): JSON!

  """Apply for loan"""
  Apply_for_loan(body: apply_loanInput): JSON!

  """Fetch loan offer from banks"""
  Fetch_loan_offer_from_banks(body: loan_offersInput): JSON!
}

type Query {
  """Fetch LoanApplication from database"""
  Fetch_LoanApplication(id: String!): JSON!

  """Fetch User from database"""
  Fetch_User(id: String!): JSON!
}

input UserInput {
  pan_number: String!
}



---- Content from: graphql.yaml ----

type: graphql
port: 4008

authn:
  jwt: # best practice is to store secrets in environment variables and not hardcode here.
    secretOrKey: <%config.jwt.secretOrKey%>
    audience: <%config.jwt.audience%>
    issuer: <%config.jwt.issuer%>

authz:
  - id: check_user_role
    fn: com.gs.transform
    args: <%inputs.user.role === 'admin'%>

on_request_validation_error: validations.request.standardResponse
on_response_validation_error: validations.request.standardResponse

log:
  attributes:
    eventsource_type: graphql

---- Content from: http.graphql ----



---- Content from: http.yaml ----

type: express
port: 3000

# limits of sile size and body
request_body_limit: 20000 #bytes
file_size_limit: 200000 #bytes

#jwt or oauth2 settings to run by default on every event
authn:
  jwt: # best practice is to store secrets in environment variables and not hardcode here.
    secretOrKey: <%config.jwt.secretOrKey%>
    audience: <%config.jwt.audience%>
    issuer: <%config.jwt.issuer%>

# authorization policies to run by default on every event
authz:
  - id: check_user_role
    fn: com.gs.transform
    args: <%inputs.user.role === 'admin' || inputs.user.role === 'manager'%>

# validation error handling, to transform error responses
on_request_validation_error: validations.request.standardResponseyml
# on_response_validation_error:
#   - id: response_validation_error_handler
#     fn: com.gs.return
#     args: 
#       success: false
#       code: 500
#       data: <%inputs%>

log:
  attributes:
    eventsource_type: http

docs: #swagger information
  endpoint: /api-docs #the endpoint in which swagger UI will run
  info:
    title: My Lending Project
    description: This is a lending microservice API.
    termsOfService: 'http://myfintech.com/terms/'
    contact:
      name: API Support
      url: 'http://www.myfintech.com/support'
      email: support@myfintech.com
    license:
      name: Apache 2.0
      url: 'https://www.apache.org/licenses/LICENSE-2.0.html'
    version: '1.0.0'
  servers:
    - url: 'http://localhost:3000'
      description: Public API server
    - url: 'http://localhost:3001'
      description: Internal API server


---- Content from: kafka.yaml ----

type: kafka
clientId: <% config.kafka.client_id %>
brokers: <% config.kafka.brokers %>
log:
  attributes:
    eventsource_type: kafka

---- Content from: create.yaml ----

summary: Create LoanApplication
tasks:
  - id: lending_service_db_loanapplication_create
    fn: datasource.lending_service_db.LoanApplication.create
    args:
      data: <% inputs.body %>
    on_error:
      continue: false
      response:
        success: false
        code: 500
        data:
          error: <%outputs.lending_service_db_user_create?.data%>
    caching:
      after:
        datasource: in_mem_cache #the name of the datasource instance to use instead of default cache
        key: <%'LoanApplication_' + outputs.lending_service_db_loanapplication_create?.data?.id%> # <Optional. Key name which is used to read from and write cache result of this task in applicable cache. Also see noRead and noWrite flags>
        #invalidate: # <Key name which we want to delete/remove from cache e.g. this feature can be used in CRUD types task. While delete operation, invalidate the cache of read or update task>
        cache_on_failure: false # <true|false, whether you want to cache the failure result or not. By default, it is false>
        #options: #Optional
        #  EX: 200 # <timer in seconds, until the cached result is valid> #Can pass any of RedisOptions, if supported by the specific caching Datasource 
    logs:
      before:
        message: About to create LoanApplication
        level: debug
        attributes:
          fn_event_type: create
          fn_entity_type: LoanApplication
          fn_bank_name: <%inputs.body.bank_name%>
          fn_user_id: <%inputs.body.userId%>
      after:
        message: Created LoanApplication
        level: debug
        attributes:
          fn_entity_id: <% outputs.lending_service_db_loanapplication_create.data.id %>
          fn_event_type: created
          fn_entity_type: LoanApplication
          fn_bank_name: <%inputs.body.bank_name%>
          fn_user_id: <%inputs.body.userId%>
        params:
          response: <%outputs.lending_service_db_loanapplication_create.data%>


---- Content from: delete.yaml ----

summary: Delete LoanApplication
tasks:
  - id: lending_service_db_loanapplication_delete
    fn: datasource.lending_service_db.LoanApplication.delete
    args:
      where:
        id: <% parseInt(inputs.params.id) %>
    caching:
      after:
        invalidate: <%'LoanApplication_' + inputs.params.id%> # <Key name which we want to delete/remove from cache e.g. this feature can be used in CRUD types task. While delete operation, invalidate the cache of read or update task>
    logs:
      before:
        message: About to delete LoanApplication
        level: debug
        attributes:
          fn_event_type: delete
          fn_entity_type: LoanApplication
          fn_entity_id: <%inputs.params.id%>
      after:
        message: Deleted LoanApplication
        level: debug
        attributes:
          fn_entity_id: <%inputs.params.id%>
          fn_event_type: deleted
          fn_entity_type: LoanApplication
        params:
          response: <%outputs.lending_service_db_loanapplication_delete.data%>

---- Content from: one.yaml ----

summary: Fetch LoanApplication
tasks:
  - id: lending_service_db_loanapplication_one
    fn: datasource.lending_service_db.LoanApplication.findUnique
    args:
      where:
        id: <% parseInt(inputs.params.id) %>
    caching:
      before:
        # datasource: in_mem_cache #the name of the datasource instance to use instead of default cache
        key: <%'LoanApplication_' + inputs.params.id%> # Optional. Key name which is used to read from and write cache result of this task in applicable cache.
      after:
        key: <%'LoanApplication_' + inputs.params.id%> # Optional. Key name which is used to write to cache result of this task in applicable cache.
        #invalidate: # <Key name which we want to delete/remove from cache e.g. this feature can be used in CRUD types task. While delete operation, invalidate the cache of read or update task>
        #options: #Optional
        #  EX: 200 # <timer in seconds, until the cached result is valid> #Can pass any of RedisOptions, if supported by the specific caching Datasource 
        cache_on_failure: false # <true|false, whether you want to cache the failure result or not. By default, it is false>
    
    logs:
      before:
        message: About to get LoanApplication by id
        level: debug
        attributes:
          fn_event_type: find_one
          fn_entity_type: LoanApplication
          fn_entity_id: <%inputs.params.id%>
      after:
        message: Find one LoanApplication Response
        level: debug
        attributes:
          fn_entity_id: <%inputs.params.id%>
          fn_event_type: find_one
          fn_entity_type: LoanApplication
          fn_found_by_id: <%inputs.success === true && !!outputs.lending_service_db_loanapplication_one.data%>
        params:
          response: <%outputs.lending_service_db_loanapplication_one.data%>


---- Content from: search.yaml ----

summary: Fetch many LoanApplication
tasks:
  - id: lending_service_db_loanapplication_search
    fn: datasource.lending_service_db.LoanApplication.findMany
    args: <%inputs.body%>
    caching: # In case of search be careful of caching because results may vary for same query between two searches
      before:
        datasource: in_mem_cache #the name of the datasource instance to use instead of default cache
        key: <%'LoanApplication_' + JSON.stringify(inputs.body)%> # Optional. Key name which is used to read from cache result of this task in applicable cache.
      after:
        key: <%'LoanApplication_' + JSON.stringify(inputs.body)%> # Optional. Key name which is used to write result of this task in applicable cache.
        datasource: in_mem_cache #the name of the datasource instance to use instead of default cache
        cache_on_failure: false # <true|false, whether you want to cache the failure result or not. By default, it is false>
        options: #Optional
          EX: 200 # <timer in seconds, until the cached result is valid> #Can pass any of RedisOptions, if supported by the specific caching Datasource 
    logs:
      before:
        message: About to search for LoanApplications in task
        level: debug
        attributes:
          fn_event_type: search
          fn_entity_type: LoanApplication
      after:
        message: Search LoanApplication Task Response
        level: debug
        attributes:
          fn_event_type: search
          fn_entity_type: LoanApplication
        params:
          response: <%outputs.lending_service_db_loanapplication_search.data%>

---- Content from: update.yaml ----

summary: Update LoanApplication
tasks:
  - id: lending_service_db_loanapplication_update
    fn: datasource.lending_service_db.LoanApplication.update
    args:
      where:
        id: <% parseInt(inputs.params.id) %>
      data: <% inputs.body %>
    
    caching:
      after:
        invalidate: <%'LoanApplication_' + inputs.params.id%> 
        cache_on_failure: false
    
    logs:
      before:
        message: About to update LoanApplication in task
        level: debug
        attributes:
          fn_event_type: update
          fn_entity_type: LoanApplication
          fn_bank_name: <%inputs.body.bank_name%>
          fn_user_id: <%inputs.body.userId%>
      after:
        message: Created LoanApplication
        level: debug
        attributes:
          fn_entity_id: <% outputs.lending_service_db_loanapplication_update.data.id %>
          fn_event_type: updated
          fn_entity_type: LoanApplication
          fn_bank_name: <%inputs.body.bank_name%>
          fn_user_id: <%inputs.body.userId%>
        params:
          response: <%outputs.lending_service_db_loanapplication_update.data%>

---- Content from: create.yaml ----

summary: Create User
tasks:
  - id: lending_service_db_user_create
    fn: datasource.lending_service_db.User.create
    args:
      data: <% inputs.body %>
    on_error:
      continue: false
      # response: # generate custom response on the error
      #   success: false
      #   code: 500
      #   data:
      #     error: <%outputs.lending_service_db_user_create.data%>
      # tasks: # You can also give a series of tasks here
      #   - id: create_user_error_handler
      #     fn: com.gs.return
      #     args:
      #       success: false
      #       code: 500
      #       error: <%outputs.lending_service_db_user_create.data%>
    caching:
      after:
        datasource: in_mem_cache #the name of the datasource instance to use instead of default cache
        key: <%'User_' + outputs.lending_service_db_user_create?.data?.id%> # <Optional. Key name which is used to read from and write cache result of this task in applicable cache. Also see noRead and noWrite flags>
        cache_on_failure: false # <true|false, whether you want to cache the failure result or not. By default, it is false>
        #options: #Optional
        #  EX: 200 # <timer in seconds, until the cached result is valid> #Can pass any of RedisOptions, if supported by the specific caching Datasource 
    logs:
      before:
        message: About to create user in task
        level: debug
        attributes:
          fn_event_type: create
          fn_entity_type: user
          fn_user_pan_number: <%inputs.body.pan_number%>
      after:
        message: Created user in task
        level: debug
        attributes:
          fn_entity_id: <% outputs.lending_service_db_user_create.data.id %>
          fn_event_type: created
          fn_entity_type: user
          fn_user_pan_number: <%inputs.body.pan_number%>
        params:
          response: <%outputs.lending_service_db_user_create.data%>

---- Content from: delete.yaml ----

summary: Delete User
tasks:
  - id: lending_service_db_user_delete
    fn: datasource.lending_service_db.User.delete
    args:
      where:
        id: <% parseInt(inputs.params.id) %>
    
    caching:
      after:
        invalidate: <%'LoanApplication_' + inputs.params.id%> # <Key name which we want to delete/remove from cache e.g. this feature can be used in CRUD types task. While delete operation, invalidate the cache of read or update task>
        cache_on_failure: false
    logs:
      before:
        message: About to delete User in task
        level: debug
        attributes:
          fn_event_type: delete
          fn_entity_type: User
          fn_entity_id: inputs.params.id
      after:
        message: Deleted User in task
        level: debug
        attributes:
          fn_entity_id: <%inputs.params.id%>
          fn_event_type: delete
          fn_entity_type: User
        params:
          response: <%outputs.lending_service_db_user_delete.data%>

---- Content from: one.yaml ----

summary: Fetch User
tasks:
  - id: lending_service_db_user_one
    fn: datasource.lending_service_db.User.findUnique
    args:
      where:
        id: <% parseInt(inputs.params.id) %>
    logs:
      before:
        message: About to get user from id
        level: debug
        attributes:
          fn_event_type: find_one
          fn_entity_type: User
          fn_entity_id: <%inputs.params.id%>
      after:
        message: Find one reponse for User in task
        level: debug
        attributes:
          fn_event_type: find_one
          fn_entity_type: User
          fn_entity_id: <%inputs.params.id%>
        params:
          response: <%outputs.lending_service_db_user_one.data%>
    caching:
      before:
        # datasource: in_mem_cache #the name of the datasource instance to use instead of default cache
        key: <%'User_' + inputs.params.id%> # Optional. Key name which is used to read from and write cache result of this task in applicable cache.
      after:
        key: <%'User_' + inputs.params.id%> # Optional. Key name which is used to write to cache result of this task in applicable cache.
        #invalidate: # <Key name which we want to delete/remove from cache e.g. this feature can be used in CRUD types task. While delete operation, invalidate the cache of read or update task>
        #options: #Optional
        #  EX: 200 # <timer in seconds, until the cached result is valid> #Can pass any of RedisOptions, if supported by the specific caching Datasource 
        cache_on_failure: false # <true|false, whether you want to cache the failure result or not. By default, it is false>
    

---- Content from: search.yaml ----

summary: Fetch many User
tasks:
  - id: lending_service_db_user_search
    fn: datasource.lending_service_db.User.findMany
    args: <%inputs.body%>
    authz:
      - id: authz_cases
        fn: com.gs.switch
        value: <%inputs.user.role%>
        cases:
          admin:
            - fn: com.gs.transform
              args:
                success: true # Full access
                # data:
                #   no_access: ['id', 'pan_number', 'loanApplications']
          manager:
            - fn: com.gs.transform
              args:
                success: true #Restricted access
                data:
                  where: 
                    id: 19
                  can_access: ['pan_number']
    # caching:
    #   # datasource: in_mem_cache #the name of the datasource instance to use instead of default cache
    #   key: <%'User_' + JSON.stringify(inputs.body)%> # <Optional. Key name which is used to read from and write cache result of this task in applicable cache. Also see noRead and noWrite flags>
      #invalidate: <%inputs.params.id%> # <Key name which we want to delete/remove from cache e.g. this feature can be used in CRUD types task. While delete operation, invalidate the cache of read or update task>
      # cache_on_failure: false # <true|false, whether you want to cache the failure result or not. By default, it is false>
      #options: #Optional
      #  EX: 200 # <timer in seconds, until the cached result is valid> #Can pass any of RedisOptions, if supported by the specific caching Datasource 
      # noRead: true # <true|false. Default false. a flag to specify to not to look into cache and executing task's function nonetheless. But the response from the task is set in the key specified (unless noWrite is set to true). Set noRead to true if you don't want to use cache for this task, but want to store this tasks response as a key for accessing this task's result somewhere else>
    logs:
      before:
        message: About to search for User in task
        level: debug
        attributes:
          fn_event_type: search
          fn_entity_type: User
      after:
        message: Search User Task Response
        level: debug
        attributes:
          fn_event_type: search
          fn_entity_type: User
        params:
          response: <%outputs.lending_service_db_user_search.data%>  


---- Content from: update.yaml ----

summary: Update User
tasks:
  - id: lending_service_db_user_update
    fn: datasource.lending_service_db.User.update
    args:
      where:
        id: <% parseInt(inputs.params.id) %>
      data: <% inputs.body %>
    caching:
      after:
        invalidate: <%'User_' + outputs.lending_service_db_loanapplication_create.data.id%>
        cache_on_failure: false
    logs:
      before:
        message: About to update User in task
        level: debug
        attributes:
          fn_event_type: update
          fn_entity_type: User
          fn_pan_number: <%inputs.body.pan_number%>
          fn_entity_id: <%inputs.params.id%>
      after:
        message: Created LoanApplication
        level: debug
        attributes:
          fn_entity_id: <%inputs.params.id%>
          fn_event_type: updated
          fn_entity_type: User
          fn_pan_number: <%inputs.body.pan_number%>
        params:
          response: <%outputs.lending_service_db_user_update.data%>


---- Content from: kafka_to_db.yaml ----

summary: push scf data into salesforce
id: kafka_to_db
tasks:
  - id: db_user_create
    summary: Create user in the database
    fn: datasource.lending_service_db.User.create
    args:
      data:
        pan_number: <% inputs.body.pan_number%>
    on_error:
      continue: false
    logs:
      before:
        level: info
        message: Creating user in the database
        attributes:
          inputs_body: <%inputs.body%>
      after:
        level: info
        message: Created user in the database
        attributes:
          pan_number: <%inputs.body.pan_number%>
          db_response: <%outputs.db_user_create.data%>
  - id: lending_service_db_loanapplication_create
    fn: datasource.lending_service_db.LoanApplication.create
    args:
      data:
        userId: <%outputs.db_user_create.data.id%> # use id from previous task where user is created
        status: approved # e.g. "pending", "approved", "rejected"
        amount: <%inputs.body.amount%>
        interest: <%inputs.body.interest_rate%>
        duration: <%inputs.body.duration%>
        bank_name: <%inputs.body.bank_name%>
    logs:
      before:
        level: info
        message: Creating loan app in the database
        attributes:
          userId: <%outputs.db_user_create.data.id%> # use id from previous task where user is created
          status: approved # e.g. "pending", "approved", "rejected"
          amount: <%inputs.body.amount%>
          interest: <%inputs.body.interest%>
          duration: <%inputs.body.duration%>
          bank_name: <%inputs.body.bank_name%>
      after:
        level: info
        message: Created loan app in the database
        attributes:
          userId: <%outputs.db_user_create.data.id%> # use id from previous task where user is created
          status: approved # e.g. "pending", "approved", "rejected"
          amount: <%inputs.body.amount%>
          interest: <%inputs.body.interest%>
          duration: <%inputs.body.duration%>
          bank_name: <%inputs.body.bank_name%>
          loan_application_id: <%outputs.lending_service_db_loanapplication_create.data.id%>
        

---- Content from: salesforceAuthToken.ts ----

import { GSContext, PlainObject } from "@godspeedsystems/core";
import config from 'config';

const axios = require('axios');
const client = axios.create({
  headers: {
    "Content-Type": "application/json"
  }
});

module.exports = async function (dsConfig: PlainObject,ctx: GSContext) {
  try {
    const res = await client({
      method: 'post',
      url: config.salesforce.auth_url,
      params: {
        client_id: config.salesforce.query_params.client_id,
        grant_type: config.salesforce.query_params.grant_type,
        password: config.salesforce.query_params.password,
        username: config.salesforce.query_params.username,
        client_secret: config.salesforce.query_params.client_secret
      }
    })
    const headers = {
      "Authorization": `Bearer ${res.data.access_token}`
    };
    // ctx.childLogger.error('Auth token successfully refreshed and following headers set: %o', Object.keys(headers));
    return headers;
  } catch (error) {
    ctx?.logger.error('Error in refreshing token for OS1 %o', error);
    throw error;
  }
}

---- Content from: check.yaml ----

summary: push scf data into salesforce
id: healthcheck
tasks:
  - id: healthcheck
    # If this is running it will return true
    fn: com.gs.return
    args:
      code: 200
      data: <%'Hello ' + inputs.body.name%>

---- Content from: check_ts.ts ----

import { GSContext, PlainObject } from "@godspeedsystems/core";

export default function (ctx: GSContext, args: PlainObject) {
    //@ts-ignore
    const {
        inputs: {
            data: {
                params, body, query, user, headers
            }
        }, 
        childLogger, 
        logger,
        outputs, 
        functions, 
        datasources,
        config,
        mappings
    }: {
        inputs: {
            data: {
                params: PlainObject,
                body: PlainObject,
                query: PlainObject,
                user: PlainObject,
                headers: PlainObject
            }
        }, 
        childLogger: any, // Define CustomLogger if necessary
        logger: any,
        outputs: PlainObject, // Adjust the type accordingly
        functions: PlainObject, // Adjust the type accordingly
        datasources: PlainObject, // Adjust the type accordingly
        config: PlainObject,
        mappings: PlainObject
    } = ctx;
    
    // Will print with workflow_name and task_id attributes
    childLogger.info('Server is running healthy');
    // Will print without workflow_name and task_id attributes
    logger.info('Inputs object \n user %o query %o body %o headers %o params %o', user, query, body, headers, params);
    logger.info('Outputs object has outputs from previous tasks with given ids %o', Object.keys(outputs));
    logger.info('Datasources object has following datasource clients %o', Object.keys(datasources));
    logger.info('Total functions found in the project %s', Object.keys(functions).length)
    
    return {
        data: 'Its working! ' + body.name,
        code: 200,
        // success: true,
        // headers: {
        //     custom_response_header: 'something'
        // }
    }
}

---- Content from: create.ts ----

import { GSContext, GSStatus, PlainObject } from "@godspeedsystems/core";
import { PrismaClient } from "@prisma/client";


module.exports = async(ctx: GSContext, args: PlainObject) => {
    const {
        inputs: {
            data: {
                params, body, query, user, headers
            }
        }, 
        childLogger, 
        logger,
        outputs, 
        functions, 
        datasources
    } = ctx;

    const client: PrismaClient = datasources.lending_service_db.client;

    const res = await client.LoanApplication.create({data:body});

    return new GSStatus(
        true, 
        201, 
        'Successfully created new Loan Application', 
        res, 
        {
            custom_header_1: 'something'
        }
    );

    //SAME AS
    
    // return {
    //     code: 201,
    //     data: res,
    //     success: true,
    //     message: 'Successfully created new Loan Application',
    //     headers: {
    //         custom_header_1: 'something'
    //     }
    // }
};

---- Content from: delete.ts ----

import { GSContext, GSStatus } from "@godspeedsystems/core";


module.exports = async(ctx: GSContext) => {
    const {params} = ctx.inputs.data;
    const {datasources}  = ctx;
    const res = await datasources.lending_service_db.client.LoanApplication.delete({where:{id:parseInt(params.id)}})
    return new GSStatus(true, 202, 'successfully deleted Loan Application', res, undefined);
};

---- Content from: one.ts ----

import { GSContext, GSStatus } from "@godspeedsystems/core";


module.exports = async(ctx: GSContext) => {
    const {params} = ctx.inputs.data;
    const {datasources}  = ctx;
    const res = await datasources.lending_service_db.client.LoanApplication.findUnique({where:{id:parseInt(params.id)}})
    return new GSStatus(true, 200, 'Successfully fetched Loan Application by id.', res || {}, undefined);
};

---- Content from: search.ts ----

import { GSContext, GSStatus } from "@godspeedsystems/core";
import { PrismaClient } from "@prisma/client";


module.exports = async(ctx: GSContext) => {
    const {datasources}  = ctx;
    const client: PrismaClient = datasources.lending_service_db.client;
    const res = await client.LoanApplication.findMany(ctx.inputs.data.body);
    return new GSStatus(true, 200, 'successfully fetched Loan Applications list', res, undefined);
};

---- Content from: update.ts ----

import { GSContext, GSStatus } from "@godspeedsystems/core";


module.exports = async(ctx: GSContext) => {
    const {body} = ctx.inputs.data;
    const {params} = ctx.inputs.data;
    const {datasources}  = ctx;
    const res = await datasources.lending_service_db.client.LoanApplication.update({where:{id:parseInt(params.id)},data:body})
    return new GSStatus(true, 204, 'successfully updated Loan Application.', res, undefined);
};

---- Content from: create.yaml ----

summary: Create LoanApplication
tasks:
  - id: lending_service_db_loanapplication_create
    fn: datasource.<% config.datasourceDB.name %>.LoanApplication.create
    args:
      data: <% inputs.body %>


---- Content from: delete.yaml ----

summary: Delete LoanApplication
tasks:
  - id: lending_service_db_loanapplication_delete
    fn: datasource.lending_service_db.LoanApplication.delete
    args:
      where:
        id: <% parseInt(inputs.params.id) %>


---- Content from: one.yaml ----

summary: Fetch LoanApplication
tasks:
  - id: lending_service_db_loanapplication_one
    fn: datasource.lending_service_db.LoanApplication.findUnique
    args:
      where:
        id: <% parseInt(inputs.params.id) %>


---- Content from: search.yaml ----

summary: Fetch many LoanApplication
tasks:
  - id: lending_service_db_loanapplication_search
    fn: datasource.lending_service_db.LoanApplication.findMany
    args: {}


---- Content from: update.yaml ----

summary: Update LoanApplication
tasks:
  - id: lending_service_db_loanapplication_update
    fn: datasource.lending_service_db.LoanApplication.update
    args:
      where:
        id: <% parseInt(inputs.params.id) %>
      data: <% inputs.body %>


---- Content from: create.ts ----

import { GSContext, GSStatus } from "@godspeedsystems/core";
// import { PrismaClient } from "@prisma/client";
const pathString: string = `${process.cwd()}/dist/datasources/prisma-clients/lending_service_db`;
// console.log(this.config.name, pathString)
const { Prisma, PrismaClient } = require(pathString);

module.exports = async(ctx: GSContext) => {
    const {body} = ctx.inputs.data;
    const {datasources}  = ctx;
    const res = await datasources.lending_service_db.client.User.create({data:body})
    return new GSStatus(true, 201, undefined, res);
};

---- Content from: delete.ts ----

import { GSContext, GSStatus } from "@godspeedsystems/core";


module.exports = async(ctx: GSContext) => {
    const {params} = ctx.inputs.data;
    const {datasources}  = ctx;
    const res = await datasources.lending_service_db.client.User.delete({where:{id:parseInt(params.id)}})
    return new GSStatus(true, 202, 'successfully deleted user', res, undefined);
};

---- Content from: one.ts ----

import { GSContext, GSStatus } from "@godspeedsystems/core";


module.exports = async(ctx: GSContext) => {
    const {params} = ctx.inputs.data;
    const {datasources}  = ctx;
    const res = await datasources.lending_service_db.client.User.findUnique({where:{id:parseInt(params.id)}})
    return new GSStatus(true, 200, 'Successfully fetched user by id', res, undefined);
};

---- Content from: search.ts ----

import { GSContext, GSStatus } from "@godspeedsystems/core";


module.exports = async(ctx: GSContext) => {
    const {datasources}  = ctx;
    const res = await datasources.lending_service_db.client.User.findMany(ctx.inputs.data?.body);
    return new GSStatus(true, 200, 'successfully fetched users list', res, undefined);
};

---- Content from: update.ts ----

import { GSContext, GSStatus } from "@godspeedsystems/core";


module.exports = async(ctx: GSContext) => {
    const {body} = ctx.inputs.data;
    const {params} = ctx.inputs.data;
    const {datasources}  = ctx;
    const res = await datasources.lending_service_db.client.User.update({where:{id:parseInt(params.id)},data:body})
    return new GSStatus(true, 204, 'successfully updated user.', res, undefined);
};

---- Content from: create.yaml ----

summary: Create User
tasks:
  - id: lending_service_db_user_create
    fn: datasource.lending_service_db.User.create
    args:
      data: <% inputs.body %>


---- Content from: delete.yaml ----

summary: Delete User
tasks:
  - id: lending_service_db_user_delete
    fn: datasource.lending_service_db.User.delete
    args:
      where:
        id: <% parseInt(inputs.params.id) %>


---- Content from: one.yaml ----

summary: Fetch User
tasks:
  - id: lending_service_db_user_one
    fn: datasource.lending_service_db.User.findUnique
    args:
      where:
        id: <% inputs.params.id %>


---- Content from: search.yaml ----

summary: Fetch many User
tasks:
  - id: lending_service_db_user_search
    fn: datasource.lending_service_db.User.findMany
    args: {}


---- Content from: update.yaml ----

summary: Update User
tasks:
  - id: lending_service_db_user_update
    fn: datasource.lending_service_db.User.update
    args:
      where:
        id: <% parseInt(inputs.params.id) %>
      data: <% inputs.body %>


---- Content from: create_account_lms.yaml ----

summary: Create user loan account in the LMS 
id: create_loan_account
tasks:
  - id: create_account_lms
    description: Fetching loan offers
    fn: datasource.lms.post./anything
    args: 
      data: <%inputs%>

---- Content from: create_account_lms_ts.ts ----

import { GSContext, GSDataSource, logger, PlainObject } from "@godspeedsystems/core";

export default async function (ctx: GSContext, args: {loan_offer: PlainObject, pan_number: string}) {
    const client: GSDataSource = ctx.datasources.lms;
    //No need to write boilerplate for retry and token refresh here
    const res =  await client.execute(ctx, {
        meta: {
            method: 'post',
            url: '/anything',
        },
        data: args,
        headers:{}
    });
    return res;
};

---- Content from: kyc.yaml ----

summary: User KYC verification 
id: rule-engine_datasource_verify_kyc
tasks:

  - id: verify_kyc
    description: verify user kyc details
    fn: datasource.kyc.post./anything
    args:
      data:
        pan_number: <%inputs.body.pan_number%>
  
  - id: tranform_kyc_verification_data
    description: transforming response from rule-engine kyc details
    fn: com.gs.transform
    args:
      data: 
        applied_for: <% inputs.body.pan_number%>
        message: kyc verification done


---- Content from: upload_document.ts ----

// # summary: upload user document
// # id: rule-engine_datasource_verify_user_document
// # tasks:
// #   - id: verify_user_document
// #     description: document verification against loan
// #     fn: datasource.aws.s3.putObject
// #     args:
// #       Body: <% inputs.body.file %>
// #       Bucket: 'userdocs123'
//   # - id: tranform_loan_data
//   #   description: transforming response from rule-engine
//   #   fn: com.gs.transform
//   #   args:
//   #     data: 
//   #       applied_for: <% outputs.verify_user_document %>
//   #       message: successfully uploaded document and verified
import { GSContext, GSStatus } from "@godspeedsystems/core";
import fs from 'fs'

module.exports = async (ctx: GSContext) => {
  const { files: { panCardFile } } = ctx.inputs.data;
  const { datasources, logger } = ctx;
  try {
    return new Promise((resolve, reject) => {
      fs.readFile(panCardFile.tempFilePath, async function (err, data) {
        if (err) {
        resolve(new GSStatus(false, 500, 'S3 document upload failed', { error: { message: err.message } }));

        } // Something went wrong!
        const contentType = ctx.inputs.data.headers['content-type']
        var params = {
          Key: panCardFile.name,
          Body: data,
          Bucket: 'userdocs123',
          ContentType: contentType,
        };

        const res = await datasources.aws.client.s3.putObject(params);

        resolve(new GSStatus(true, 200, 'successfully uploaded document for verification', res, undefined))

      })
    });

  } catch (e: any) {
    logger.error('S3 document upload failed %o', e)
    return new GSStatus(false, 500, 'S3 document upload failed', { error: { message: e.message } })
  }

};

---- Content from: apply_for_loan.yaml ----

# Complete the full loan application journey 
id: apply_loan_wflw
tasks:
  - id: fetch_loan_offers
    # Fetching loan offers from rule engine for the given bank and pan card
    fn: datasource.rule_engine.post./anything
    args:
      data:
        bank_name: <%inputs.body.bank_name%>
        pan_number: <%inputs.body.pan_number%>
        amount: 100.00
        interest_rate: 10.5
        duration: 12 #months
    on_error:
      continue: false
    retry: # By default the datasource has constant retry set in its yaml. Here we override the retry to exponential
      when: # an and condition between status and message.
        status: [500, 503] # an array or single value of codes (optional). Default 500
        message: Retry later # Retry when response has this message
      max_attempts: 5
      type: exponential
      min_interval: PT5s
      max_internal: PT15s
    logs:
      before:
        level: info
        message: Fetching loan offer from bank
        attributes:
          bank_name: <%inputs.body.bank_name%>
          pan_number: <%inputs.body.pan_number%>
      after:
        level: info
        message: Re-fetched loan offer from bank
        attributes:
          bank_name: <%inputs.body.bank_name%>
          pan_number: <%inputs.body.pan_number%>

  - id: kyc_details_verify
    # Verify the pan number of the user
    fn: los.loan_application_journey.kyc
    args: <% inputs %>
    logs:
      before:
        level: info
        message: Initiating KYC
        attributes:
          bank_name: <%inputs.body.bank_name%>
          pan_number: <%inputs.body.pan_number%>
      after:
        level: info
        message: KYC done for customer
        attributes:
          bank_name: <%inputs.body.bank_name%>
          pan_number: <%inputs.body.pan_number%>

  - id: upload_documents
    # Upload user documents to S3 storage
    fn: los.loan_application_journey.upload_document
    args: <% inputs %>
    on_error:
      continue: false
    logs:
      before:
        level: info
        message: Initiating document upload to S3
        attributes:
          bank_name: <%inputs.body.bank_name%>
          pan_number: <%inputs.body.pan_number%>
      after:
        level: info
        message: Uploaded documents to S3
        attributes:
          bank_name: <%inputs.body.bank_name%>
          pan_number: <%inputs.body.pan_number%>

  - id: create_loan_account_in_bank
    # Create loan account within the bank's system
    fn: datasource.my_bank.post./anything
    args:
      data: 
        applied_for: <% outputs.fetch_loan_offers.data.json %>
        message: successfully applied
        id: <%randomInt(1, 10000)%>
    logs:
      before:
        level: info
        message: Creating loan account in bank
        attributes:
          bank_name: <%inputs.body.bank_name%>
          pan_number: <%inputs.body.pan_number%>
      after:
        level: info
        message: Created account in bank 
        attributes:
          bank_name: <%inputs.body.bank_name%>
          pan_number: <%inputs.body.pan_number%>


  - id: create_account_lms
    # Create user account in the LMS. Invoke another sub-workflow
    fn: los.loan_application_journey.create_account_lms_ts
    args:
      loan_offer: <% outputs.fetch_loan_offers.data.json %>
      pan_number: <% inputs.body.pan_number %>
      id: <%randomInt(1, 10000)%>
    logs:
      before:
        level: info
        message: Creating loan application in LMS
        attributes:
          bank_name: <%inputs.body.bank_name%>
          pan_number: <%inputs.body.pan_number%>
      after:
        level: info
        message: Created account in LMS. Loan application journey completed.
        attributes:
          bank_name: <%inputs.body.bank_name%>
          pan_number: <%inputs.body.pan_number%>

  - id: publish_loan_onboarding_data
    # Send new user and loan details to Kafka
    fn: datasource.kafka.producer
    args:
      topic: new_loan
      message: <% outputs.fetch_loan_offers.data.json %>
    logs:
      before:
        level: info
        message: Sending event to kafka
        attributes:
          message_body: <%outputs.fetch_loan_offers.data.json%>
      after:
        level: info
        message: Sent event to kafka
        attributes:
          message_body: <%outputs.fetch_loan_offers.data.json%>
  
  - id: return_response
    # combine and return response
    fn: com.gs.transform
    args:
      data:
        message: Loan account created. Event published on Kafka.
        bank:
          name: <%inputs.body.bank_name%>
          vpa_id: <%outputs.create_loan_account_in_bank.data.json.id%>
        lms:
          lms_account_id: <%outputs.create_account_lms.data.json.id%>

---- Content from: fetch_loan_offers.yaml ----

summary: fetching loans offered by different banks via credit score and rule-engine datasource 
id: rule-engine_datasource_loan_fetch
tasks:
  - id: fetch_loans
    description: Fetching loan offers based on credit score of the user and rules set by different banks
    fn: datasource.rule_engine.post./anything
    args:
      data:
        - bank_name: my_bank
          loan_amount: 100.00
          interest_rate: 10.5
          duration: 12 #months
        - bank_name: some_other_bank
          loan_amount: 50.00
          interest_rate: 12.5
          duration: 12 #months
          

  - id: tranform_loan_data
    description: transforming response from rule-engine
    fn: com.gs.transform
    args:
      data: 
        message: Following loan offers available for the given pan card based on credit score
        loan_offers: <% outputs.fetch_loans.data.json %>


---- Content from: authn.ts ----


import { logger } from "@godspeedsystems/core";
import qs from 'qs';

const axios = require('axios');
const client = axios.create({
    headers: {
        'Content-Type': 'application/json'
    }
});
/**
 * Generate and return all the headers which are required to be sent
 * in the API calls which require authentication tokens
 */
module.exports = async function (ctx: any) {
    try {
        const res = await client({
            method: 'get',
            url: `https://httpbin.org/anything`,
            data: {
                "Authorization": 'my_bank_access_token'
            }
        })
        // Retrieve the authn tokens
        const headers = {
            "Authorization": res.data.access_token || 'my_bank_access_token'
        };
       
        logger.info('Auth token successfully refreshed and following headers set: %o', Object.keys(headers));
        return headers;
    } catch (error) {
        
        logger.error('Error in refreshing token %o', error);
        throw error;
    }
}

---- Content from: standardResponse.ts ----

import { GSContext, logger } from "@godspeedsystems/core";

export default function (ctx: GSContext) {
    // logger.error(ctx.inputs.data.validation_error)
    return {
        success: false,
        data: ctx.inputs.data,
        code: 400
    }
}

---- Content from: standardResponseyml.yaml ----

tasks:
  - id: validation_error
    description: here you can customize the response when a request validation error happens
    fn: com.gs.transform
    args:
      success: false
      code: 400
      data: #can manipulate response data here
        <%inputs.validation_error%>
    # logs:
    #   before:
    #     level: info
    #     message: "something went wrong"
    #     attributes:
    #       info: <%inputs%>

---- Content from: default.yaml ----

defaults:
  on_error: #in workflow tasks, if a task has error, whether to continue to next task or not
    continue: false
  lang: js # fdefault scripting language. other option is coffee

---- Content from: index.yaml ----

GENDER:
  MALE: true
  FEMALE: false

LOAN_JOURNEY:
  customized_workflow_per_lender_and_product:
    my_bank:
      flow:
        - kyc
          upload_document
          create_account
my_bank:
  auth_workflow_cookie: 'some_cookie'
          


---- Content from: xyz.yaml ----



---- Content from: brownfield.ts ----

import Godspeed, { GodspeedParams, logger, childLogger, GSStatus } from "@godspeedsystems/core";
import { PlainObject } from "@godspeedsystems/core";

// STEP1: Initialize godspeed project
const args: PlainObject = getArgs();
const params: GodspeedParams = {
    // eventsFolderPath: undefined,
    workflowsFolderPath: 'dist/functions',
    definitionsFolderPath: 'dist/definitions',
    configFolderPath: '/config',
    datasourcesFolderPath: 'dist/datasources',
    // eventsourcesFolderPath: undefined,
    mappingsFolderPath: 'dist/mappings',
    pluginsFolderPath: 'dist/plugins'
}

// create a godspeed instance
const gsApp = new Godspeed(params);


logger.info('Initializing Godspeed project');
gsApp.initialize().then(async () => {

    logger.info('Godspeed initialized');

    logger.info('Calling a Godspeed funtion with event (input) data');
    const res: GSStatus =
        await gsApp.executeWorkflow(
            "health.check", // Localted in `workflowsFolderPath` at /health/check.yaml
            {               // Pass parsed (deserialized) event information as pure jSON 
                headers: {},
                params: {},
                body: {},
                query: {},
                user: {}
            }
        );
    if (res.success) {
        logger.info('Success response from function invocation %o', res);
        //Do whatever
    } else {
        logger.error('Error response from function invocation %o', res);
        //Do whatever
    }
})
.catch(logger.error)

function getArgs() {
    const ret = process.argv.splice(3).reduce((acc: PlainObject, arg) => {
        const argSplit = arg.split('=');
        acc[argSplit[0]] = argSplit[1];
        return acc;
    }, {});
    return ret;
}

---- Content from: index.ts ----

import Godspeed from "@godspeedsystems/core";

// create a godspeed
const gsApp = new Godspeed();

// initilize the Godspeed App
// this is responsible to load all kind of entities
gsApp.initialize();


---- Content from: README.md ----

# Node.js template

This is a Node.js project.

Add your [configuration](https://codesandbox.io/docs/projects/learn/setting-up/tasks) to optimize it for [CodeSandbox](https://codesandbox.io/p/dashboard).

## Resources

- [CodeSandbox — Docs](https://codesandbox.io/docs/projects)
- [CodeSandbox — Discord](https://discord.gg/Ggarp3pX5H)


---- Content from: tsconfig.json ----

{
  "compilerOptions": {
    "target": "es6",
    "module": "commonjs",
    "outDir": "./dist",
    "rootDir": "./src",
    "strict": true,
    "moduleResolution": "node",
    "sourceMap": true,
    "esModuleInterop": true
  },
  "exclude": ["./node_modules"]
}
